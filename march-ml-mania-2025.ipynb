{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e07a1fb",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-19T21:51:56.442197Z",
     "iopub.status.busy": "2025-03-19T21:51:56.441780Z",
     "iopub.status.idle": "2025-03-19T21:51:59.312446Z",
     "shell.execute_reply": "2025-03-19T21:51:59.311334Z"
    },
    "papermill": {
     "duration": 2.879045,
     "end_time": "2025-03-19T21:51:59.314640",
     "exception": false,
     "start_time": "2025-03-19T21:51:56.435595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.impute import SimpleImputer\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5e914",
   "metadata": {
    "papermill": {
     "duration": 0.004183,
     "end_time": "2025-03-19T21:51:59.324236",
     "exception": false,
     "start_time": "2025-03-19T21:51:59.320053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2328a8b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:51:59.334541Z",
     "iopub.status.busy": "2025-03-19T21:51:59.333972Z",
     "iopub.status.idle": "2025-03-19T21:52:02.997585Z",
     "shell.execute_reply": "2025-03-19T21:52:02.996444Z"
    },
    "papermill": {
     "duration": 3.670903,
     "end_time": "2025-03-19T21:52:02.999586",
     "exception": false,
     "start_time": "2025-03-19T21:51:59.328683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "m_teams = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MTeams.csv')\n",
    "w_teams = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WTeams.csv')\n",
    "m_regular = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MRegularSeasonCompactResults.csv')\n",
    "w_regular = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WRegularSeasonCompactResults.csv')\n",
    "m_tourney = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MNCAATourneyCompactResults.csv')\n",
    "w_tourney = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WNCAATourneyCompactResults.csv')\n",
    "m_massey = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MMasseyOrdinals.csv')\n",
    "m_team_conferences = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MTeamConferences.csv')\n",
    "w_team_conferences = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WTeamConferences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e6ec80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:03.009898Z",
     "iopub.status.busy": "2025-03-19T21:52:03.009501Z",
     "iopub.status.idle": "2025-03-19T21:52:03.027693Z",
     "shell.execute_reply": "2025-03-19T21:52:03.026349Z"
    },
    "papermill": {
     "duration": 0.025764,
     "end_time": "2025-03-19T21:52:03.029889",
     "exception": false,
     "start_time": "2025-03-19T21:52:03.004125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Season', 'TeamID', 'ConfAbbrev'], dtype='object')\n",
      "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT\n",
      "0    1985      20     1228      81     1328      64    N      0\n",
      "1    1985      25     1106      77     1354      70    H      0\n",
      "2    1985      25     1112      63     1223      56    H      0\n",
      "3    1985      25     1165      70     1432      54    H      0\n",
      "4    1985      25     1192      86     1447      74    H      0\n"
     ]
    }
   ],
   "source": [
    "print(m_team_conferences.columns)\n",
    "print(m_regular.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610d114",
   "metadata": {
    "papermill": {
     "duration": 0.00406,
     "end_time": "2025-03-19T21:52:03.038619",
     "exception": false,
     "start_time": "2025-03-19T21:52:03.034559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Processing men's teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ad3980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:03.048991Z",
     "iopub.status.busy": "2025-03-19T21:52:03.048642Z",
     "iopub.status.idle": "2025-03-19T21:52:04.049705Z",
     "shell.execute_reply": "2025-03-19T21:52:04.048534Z"
    },
    "papermill": {
     "duration": 1.008782,
     "end_time": "2025-03-19T21:52:04.051723",
     "exception": false,
     "start_time": "2025-03-19T21:52:03.042941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MRegularSeasonDetailedResults.csv')\n",
    "\n",
    "# Feature Engineering\n",
    "data['WLoc'] = data['WLoc'].map({'H': 0, 'A': 1, 'N': 2})\n",
    "\n",
    "# Create target variable\n",
    "data['Outcome'] = 1  # 1 for win\n",
    "\n",
    "# Create a mirrored dataset for the losing team\n",
    "data_lose = data.copy()\n",
    "data_lose['Outcome'] = 0  # 0 for loss\n",
    "data_lose['WTeamID'], data_lose['LTeamID'] = data_lose['LTeamID'], data_lose['WTeamID']\n",
    "data_lose['WScore'], data_lose['LScore'] = data_lose['LScore'], data_lose['WScore']\n",
    "\n",
    "# Combine both datasets\n",
    "combined_data = pd.concat([data, data_lose])\n",
    "\n",
    "# Select features and target\n",
    "features = ['WTeamID', 'LTeamID', 'WScore', 'LScore', 'WLoc', 'NumOT']\n",
    "Xm = combined_data[features]\n",
    "ym = combined_data['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training and testing data\n",
    "Xm_train.to_csv('Xm_train.csv', index=False)\n",
    "Xm_test.to_csv('Xm_test.csv', index=False)\n",
    "ym_train.to_csv('ym_train.csv', index=False)\n",
    "ym_test.to_csv('ym_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3c6f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:04.062687Z",
     "iopub.status.busy": "2025-03-19T21:52:04.062252Z",
     "iopub.status.idle": "2025-03-19T21:52:18.519221Z",
     "shell.execute_reply": "2025-03-19T21:52:18.517908Z"
    },
    "papermill": {
     "duration": 14.464449,
     "end_time": "2025-03-19T21:52:18.521185",
     "exception": false,
     "start_time": "2025-03-19T21:52:04.056736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier Score men: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Load the training and testing data\n",
    "Xm_train = pd.read_csv('Xm_train.csv')\n",
    "Xm_test = pd.read_csv('Xm_test.csv')\n",
    "ym_train = pd.read_csv('ym_train.csv')\n",
    "ym_test = pd.read_csv('ym_test.csv')\n",
    "\n",
    "# Ensure y_train and y_test are 1D arrays (required for scikit-learn)\n",
    "ym_train = ym_train.values.ravel()\n",
    "ym_test = ym_test.values.ravel()\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(Xm_train, ym_train)\n",
    "\n",
    "# Make predictions on the test set (probabilities for the positive class)\n",
    "y_pred_proba_m = model.predict_proba(Xm_test)[:, 1]\n",
    "\n",
    "# Calculate the Brier score\n",
    "brier_score_m = brier_score_loss(ym_test, y_pred_proba_m)\n",
    "\n",
    "# Print the Brier score\n",
    "print(f\"Brier Score men: {brier_score_m:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68814cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:18.532001Z",
     "iopub.status.busy": "2025-03-19T21:52:18.531596Z",
     "iopub.status.idle": "2025-03-19T21:52:20.445592Z",
     "shell.execute_reply": "2025-03-19T21:52:20.444317Z"
    },
    "papermill": {
     "duration": 1.921461,
     "end_time": "2025-03-19T21:52:20.447338",
     "exception": false,
     "start_time": "2025-03-19T21:52:18.525877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file generated with 66066 rows.\n",
      "                ID  Pred\n",
      "0   2025_1101_1102  0.98\n",
      "1   2025_1101_1103  0.99\n",
      "2   2025_1101_1104  1.00\n",
      "3   2025_1101_1105  1.00\n",
      "4   2025_1101_1106  1.00\n",
      "5   2025_1101_1107  1.00\n",
      "6   2025_1101_1108  1.00\n",
      "7   2025_1101_1110  1.00\n",
      "8   2025_1101_1111  1.00\n",
      "9   2025_1101_1112  1.00\n",
      "10  2025_1101_1113  1.00\n",
      "11  2025_1101_1114  1.00\n",
      "12  2025_1101_1115  1.00\n",
      "13  2025_1101_1116  1.00\n",
      "14  2025_1101_1117  1.00\n",
      "15  2025_1101_1119  1.00\n",
      "16  2025_1101_1120  1.00\n",
      "17  2025_1101_1122  1.00\n",
      "18  2025_1101_1123  1.00\n",
      "19  2025_1101_1124  1.00\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Load data\n",
    "m_team_conferences = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/MTeamConferences.csv')\n",
    "\n",
    "# Define the seasons to process\n",
    "seasons = [2025]\n",
    "\n",
    "# Create a DataFrame to store all predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Process men's teams\n",
    "for season in seasons:\n",
    "    # Get Division-I teams for the current season\n",
    "    m_teams_season = m_team_conferences[m_team_conferences['Season'] == season]['TeamID'].unique()\n",
    "    \n",
    "    # Generate all possible matchups for the current season\n",
    "    m_matchups = list(itertools.combinations(m_teams_season, 2))\n",
    "    \n",
    "    # Create a DataFrame for the matchups\n",
    "    matchup_df = pd.DataFrame(m_matchups, columns=[\"Team1\", \"Team2\"])\n",
    "    \n",
    "    # Add season and matchup ID\n",
    "    matchup_df[\"Season\"] = season\n",
    "    matchup_df[\"ID\"] = matchup_df.apply(lambda row: f\"{row['Season']}_{min(row['Team1'], row['Team2'])}_{max(row['Team1'], row['Team2'])}\", axis=1)\n",
    "    \n",
    "    # Prepare features for prediction\n",
    "    # Assuming the model requires features like WTeamID, LTeamID, WScore, LScore, WLoc, NumOT\n",
    "    # Replace this with your actual feature generation logic\n",
    "    matchup_df[\"WTeamID\"] = matchup_df[\"Team1\"]\n",
    "    matchup_df[\"LTeamID\"] = matchup_df[\"Team2\"]\n",
    "    matchup_df[\"WScore\"] = 70  # Example: Replace with actual logic\n",
    "    matchup_df[\"LScore\"] = 65  # Example: Replace with actual logic\n",
    "    matchup_df[\"WLoc\"] = 0     # Example: Replace with actual logic\n",
    "    matchup_df[\"NumOT\"] = 0    # Example: Replace with actual logic\n",
    "    \n",
    "    # Select features for prediction\n",
    "    features = [\"WTeamID\", \"LTeamID\", \"WScore\", \"LScore\", \"WLoc\", \"NumOT\"]\n",
    "    X_test = matchup_df[features]\n",
    "    \n",
    "    # Ensure Xm_test has the same number of rows as matchup_df\n",
    "    if len(X_test) != len(matchup_df):\n",
    "        raise ValueError(f\"Feature generation error: Xm_test has {len(X_test)} rows, but matchup_df has {len(matchup_df)} rows.\")\n",
    "    \n",
    "    # Make predictions for all matchups in the current season\n",
    "    pred = model.predict_proba(X_test)[:, 1]  # Replace this with your actual model's prediction\n",
    "    \n",
    "    # Ensure predictions have the same length as matchup_df\n",
    "   # if len(pred) != len(matchup_df):\n",
    "       # raise ValueError(f\"Prediction error: Pred has {len(pred)} values, but matchup_df has {len(matchup_df)} rows.\")\n",
    "    \n",
    "    # Append the matchup ID and prediction to the list\n",
    "    matchup_df[\"Pred\"] = pred\n",
    "    all_predictions.append(matchup_df[[\"ID\", \"Pred\"]])\n",
    "\n",
    "# Concatenate all predictions into a single DataFrame\n",
    "submission_df_m = pd.concat(all_predictions, ignore_index=True)\n",
    "\n",
    "# Verify the number of rows\n",
    "#required_rows = 507108\n",
    "#if len(submission_df) < required_rows:\n",
    "  # raise ValueError(f\"Submission file has only {len(submission_df)} rows, but {required_rows} rows are required.\")\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df_m.to_csv(\"men_tournament_predictions.csv\", index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Submission file generated with {len(submission_df_m)} rows.\")\n",
    "\n",
    "print(submission_df_m.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16de194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:20.457888Z",
     "iopub.status.busy": "2025-03-19T21:52:20.457496Z",
     "iopub.status.idle": "2025-03-19T21:52:20.468990Z",
     "shell.execute_reply": "2025-03-19T21:52:20.467830Z"
    },
    "papermill": {
     "duration": 0.018896,
     "end_time": "2025-03-19T21:52:20.470914",
     "exception": false,
     "start_time": "2025-03-19T21:52:20.452018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample test features (Xm_test):\n",
      "   WTeamID  LTeamID  WScore  LScore  WLoc  NumOT\n",
      "0     1398     1120      73      78     0      0\n",
      "1     1287     1184      75      62     0      0\n",
      "2     1379     1443      67      64     0      1\n",
      "3     1458     1278      68      81     0      0\n",
      "4     1397     1272      79      88     0      0\n",
      "Features are diverse and should allow for meaningful predictions.\n"
     ]
    }
   ],
   "source": [
    "# Check the features for the test data\n",
    "print(\"Sample test features (Xm_test):\")\n",
    "print(Xm_test.head())\n",
    "\n",
    "# Check if features are constant\n",
    "if Xm_test.nunique().eq(1).any():\n",
    "    print(\"Warning: Some features are constant and may not be informative.\")\n",
    "else:\n",
    "    print(\"Features are diverse and should allow for meaningful predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e18e4fda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:20.481689Z",
     "iopub.status.busy": "2025-03-19T21:52:20.481278Z",
     "iopub.status.idle": "2025-03-19T21:52:22.638601Z",
     "shell.execute_reply": "2025-03-19T21:52:22.637218Z"
    },
    "papermill": {
     "duration": 2.164847,
     "end_time": "2025-03-19T21:52:22.640444",
     "exception": false,
     "start_time": "2025-03-19T21:52:20.475597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions sample: [1. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "Model is making diverse predictions on training data.\n"
     ]
    }
   ],
   "source": [
    "# Check model performance on the training data\n",
    "train_predictions = model.predict_proba(Xm_train)[:, 1]\n",
    "print(\"Training predictions sample:\", train_predictions[:10])\n",
    "\n",
    "# Check if training predictions are diverse\n",
    "if np.unique(train_predictions).size == 0.9:\n",
    "    print(\"Warning: Model is predicting the same value for all training samples.\")\n",
    "else:\n",
    "    print(\"Model is making diverse predictions on training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ebedf",
   "metadata": {
    "papermill": {
     "duration": 0.004303,
     "end_time": "2025-03-19T21:52:22.649761",
     "exception": false,
     "start_time": "2025-03-19T21:52:22.645458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Processing women's teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14654160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:22.660513Z",
     "iopub.status.busy": "2025-03-19T21:52:22.660041Z",
     "iopub.status.idle": "2025-03-19T21:52:23.451650Z",
     "shell.execute_reply": "2025-03-19T21:52:23.450512Z"
    },
    "papermill": {
     "duration": 0.799105,
     "end_time": "2025-03-19T21:52:23.453528",
     "exception": false,
     "start_time": "2025-03-19T21:52:22.654423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_w = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WRegularSeasonDetailedResults.csv')\n",
    "\n",
    "# Feature Engineering\n",
    "data_w['WLoc'] = data_w['WLoc'].map({'H': 0, 'A': 1, 'N': 2})\n",
    "\n",
    "# Create target variable\n",
    "data_w['Outcome'] = 1  # 1 for win\n",
    "\n",
    "# Create a mirrored dataset for the losing team\n",
    "data_lose_w = data.copy()\n",
    "data_lose_w['Outcome'] = 0  # 0 for loss\n",
    "data_lose_w['WTeamID'], data_lose['LTeamID'] = data_lose['LTeamID'], data_lose['WTeamID']\n",
    "data_lose_w['WScore'], data_lose['LScore'] = data_lose['LScore'], data_lose['WScore']\n",
    "\n",
    "# Combine both datasets\n",
    "combined_data_w = pd.concat([data_w, data_lose_w])\n",
    "\n",
    "# Select features and target\n",
    "features_w = ['WTeamID', 'LTeamID', 'WScore', 'LScore', 'WLoc', 'NumOT']\n",
    "Xw = combined_data_w[features]\n",
    "yw = combined_data_w['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(Xw, yw, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training and testing data\n",
    "Xw_train.to_csv('Xw_train.csv', index=False)\n",
    "Xw_test.to_csv('Xw_test.csv', index=False)\n",
    "yw_train.to_csv('yw_train.csv', index=False)\n",
    "yw_test.to_csv('yw_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322b1b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:23.464159Z",
     "iopub.status.busy": "2025-03-19T21:52:23.463778Z",
     "iopub.status.idle": "2025-03-19T21:52:27.810263Z",
     "shell.execute_reply": "2025-03-19T21:52:27.808654Z"
    },
    "papermill": {
     "duration": 4.353874,
     "end_time": "2025-03-19T21:52:27.812237",
     "exception": false,
     "start_time": "2025-03-19T21:52:23.458363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier Score women: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Load the training and testing data\n",
    "Xw_train = pd.read_csv('Xw_train.csv')\n",
    "Xw_test = pd.read_csv('Xw_test.csv')\n",
    "yw_train = pd.read_csv('yw_train.csv')\n",
    "yw_test = pd.read_csv('yw_test.csv')\n",
    "\n",
    "# Ensure y_train and y_test are 1D arrays (required for scikit-learn)\n",
    "yw_train = yw_train.values.ravel()\n",
    "yw_test = yw_test.values.ravel()\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(Xw_train, yw_train)\n",
    "\n",
    "# Make predictions on the test set (probabilities for the positive class)\n",
    "y_pred_proba_w = model.predict_proba(Xw_test)[:, 1]\n",
    "\n",
    "# Calculate the Brier score\n",
    "brier_score_w = brier_score_loss(yw_test, y_pred_proba_w)\n",
    "\n",
    "# Print the Brier score\n",
    "print(f\"Brier Score women: {brier_score_w:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a89aa6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:27.823368Z",
     "iopub.status.busy": "2025-03-19T21:52:27.822961Z",
     "iopub.status.idle": "2025-03-19T21:52:29.527920Z",
     "shell.execute_reply": "2025-03-19T21:52:29.526643Z"
    },
    "papermill": {
     "duration": 1.712549,
     "end_time": "2025-03-19T21:52:29.529763",
     "exception": false,
     "start_time": "2025-03-19T21:52:27.817214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file generated with 65341 rows.\n",
      "                   ID  Pred\n",
      "65321  2025_3474_3476   1.0\n",
      "65322  2025_3474_3477   1.0\n",
      "65323  2025_3474_3478   1.0\n",
      "65324  2025_3474_3479   1.0\n",
      "65325  2025_3474_3480   1.0\n",
      "65326  2025_3475_3476   1.0\n",
      "65327  2025_3475_3477   1.0\n",
      "65328  2025_3475_3478   1.0\n",
      "65329  2025_3475_3479   1.0\n",
      "65330  2025_3475_3480   1.0\n",
      "65331  2025_3476_3477   1.0\n",
      "65332  2025_3476_3478   1.0\n",
      "65333  2025_3476_3479   1.0\n",
      "65334  2025_3476_3480   1.0\n",
      "65335  2025_3477_3478   1.0\n",
      "65336  2025_3477_3479   1.0\n",
      "65337  2025_3477_3480   1.0\n",
      "65338  2025_3478_3479   1.0\n",
      "65339  2025_3478_3480   1.0\n",
      "65340  2025_3479_3480   1.0\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "w_team_conferences = pd.read_csv('/kaggle/input/march-machine-learning-mania-2025/WTeamConferences.csv')\n",
    "\n",
    "# Define the seasons to process\n",
    "seasons = [2025]\n",
    "\n",
    "# Create a DataFrame to store all predictions\n",
    "all_predictions_w = []\n",
    "\n",
    "# Process women's teams\n",
    "for season in seasons:\n",
    "    # Get Division-I teams for the current season\n",
    "    w_teams_season = w_team_conferences[w_team_conferences['Season'] == season]['TeamID'].unique()\n",
    "    \n",
    "    # Generate all possible matchups for the current season\n",
    "    w_matchups = list(itertools.combinations(w_teams_season, 2))\n",
    "    \n",
    "    # Create a DataFrame for the matchups\n",
    "    matchup_df_w = pd.DataFrame(w_matchups, columns=[\"Team1\", \"Team2\"])\n",
    "    \n",
    "    # Add season and matchup ID\n",
    "    matchup_df_w[\"Season\"] = season\n",
    "    matchup_df_w[\"ID\"] = matchup_df_w.apply(lambda row: f\"{row['Season']}_{min(row['Team1'], row['Team2'])}_{max(row['Team1'], row['Team2'])}\", axis=1)\n",
    "    \n",
    "    # Prepare features for prediction\n",
    "    # Assuming the model requires features like WTeamID, LTeamID, WScore, LScore, WLoc, NumOT\n",
    "    # Replace this with your actual feature generation logic\n",
    "    matchup_df_w[\"WTeamID\"] = matchup_df_w[\"Team1\"]\n",
    "    matchup_df_w[\"LTeamID\"] = matchup_df_w[\"Team2\"]\n",
    "    matchup_df_w[\"WScore\"] = 70  # Example: Replace with actual logic\n",
    "    matchup_df_w[\"LScore\"] = 65  # Example: Replace with actual logic\n",
    "    matchup_df_w[\"WLoc\"] = 0     # Example: Replace with actual logic\n",
    "    matchup_df_w[\"NumOT\"] = 0    # Example: Replace with actual logic\n",
    "    \n",
    "    # Select features for prediction\n",
    "    features_w = [\"WTeamID\", \"LTeamID\", \"WScore\", \"LScore\", \"WLoc\", \"NumOT\"]\n",
    "    X_test_w = matchup_df_w[features_w]\n",
    "    \n",
    "    # Ensure Xm_test has the same number of rows as matchup_df\n",
    "    if len(X_test_w) != len(matchup_df_w):\n",
    "        raise ValueError(f\"Feature generation error: Xw_test has {len(X_test_w)} rows, but matchup_df_w has {len(matchup_df_w)} rows.\")\n",
    "    \n",
    "    # Make predictions for all matchups in the current season\n",
    "    pred_w = model.predict_proba(X_test_w)[:, 1]  # Replace this with your actual model's prediction\n",
    "    \n",
    "    # Ensure predictions have the same length as matchup_df\n",
    "   # if len(pred) != len(matchup_df):\n",
    "       # raise ValueError(f\"Prediction error: Pred has {len(pred)} values, but matchup_df has {len(matchup_df)} rows.\")\n",
    "    \n",
    "    # Append the matchup ID and prediction to the list\n",
    "    matchup_df_w[\"Pred\"] = pred_w\n",
    "    all_predictions_w.append(matchup_df_w[[\"ID\", \"Pred\"]])\n",
    "\n",
    "# Concatenate all predictions into a single DataFrame\n",
    "submission_df_w = pd.concat(all_predictions_w, ignore_index=True)\n",
    "\n",
    "# Verify the number of rows\n",
    "#required_rows = 507108\n",
    "#if len(submission_df) < required_rows:\n",
    "  # raise ValueError(f\"Submission file has only {len(submission_df)} rows, but {required_rows} rows are required.\")\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df_w.to_csv(\"women_tournament_predictions.csv\", index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Submission file generated with {len(submission_df_w)} rows.\")\n",
    "\n",
    "print(submission_df_w.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3c6a0cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:29.540877Z",
     "iopub.status.busy": "2025-03-19T21:52:29.540532Z",
     "iopub.status.idle": "2025-03-19T21:52:29.551701Z",
     "shell.execute_reply": "2025-03-19T21:52:29.550423Z"
    },
    "papermill": {
     "duration": 0.018774,
     "end_time": "2025-03-19T21:52:29.553545",
     "exception": false,
     "start_time": "2025-03-19T21:52:29.534771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample test features (Xw_test):\n",
      "   WTeamID  LTeamID  WScore  LScore  WLoc  NumOT\n",
      "0     3258     3388      72      57     0      0\n",
      "1     1186     1381      82      70     2      0\n",
      "2     3313     3354      63      49     0      0\n",
      "3     3172     3203      73      54     1      0\n",
      "4     3198     3152      64      46     0      0\n",
      "Features are diverse and should allow for meaningful predictions.\n"
     ]
    }
   ],
   "source": [
    "# Check the features for the test data\n",
    "print(\"Sample test features (Xw_test):\")\n",
    "print(Xw_test.head())\n",
    "\n",
    "# Check if features are constant\n",
    "if Xw_test.nunique().eq(1).any():\n",
    "    print(\"Warning: Some features are constant and may not be informative.\")\n",
    "else:\n",
    "    print(\"Features are diverse and should allow for meaningful predictions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5563a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:29.564575Z",
     "iopub.status.busy": "2025-03-19T21:52:29.564182Z",
     "iopub.status.idle": "2025-03-19T21:52:30.494078Z",
     "shell.execute_reply": "2025-03-19T21:52:30.492947Z"
    },
    "papermill": {
     "duration": 0.937378,
     "end_time": "2025-03-19T21:52:30.495885",
     "exception": false,
     "start_time": "2025-03-19T21:52:29.558507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training predictions sample: [1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Model is making diverse predictions on training data.\n"
     ]
    }
   ],
   "source": [
    "# Check model performance on the training data\n",
    "train_predictions_w = model.predict_proba(Xw_train)[:, 1]\n",
    "print(\"Training predictions sample:\", train_predictions_w[:10])\n",
    "\n",
    "# Check if training predictions are diverse\n",
    "if np.unique(train_predictions_w).size == 1:\n",
    "    print(\"Warning: Model is predicting the same value for all training samples.\")\n",
    "else:\n",
    "    print(\"Model is making diverse predictions on training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6e03dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T21:52:30.507415Z",
     "iopub.status.busy": "2025-03-19T21:52:30.507039Z",
     "iopub.status.idle": "2025-03-19T21:52:30.694674Z",
     "shell.execute_reply": "2025-03-19T21:52:30.693450Z"
    },
    "papermill": {
     "duration": 0.1953,
     "end_time": "2025-03-19T21:52:30.696446",
     "exception": false,
     "start_time": "2025-03-19T21:52:30.501146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is diverse.\n",
      "(131407, 2)\n"
     ]
    }
   ],
   "source": [
    "final_submission = pd.concat([submission_df_m, submission_df_w], axis=0)\n",
    "\n",
    "# Check if features are constant\n",
    "if final_submission.nunique().eq(1).any():\n",
    "    print(\"Warning: Some data is constant and may not be informative.\")\n",
    "else:\n",
    "    print(\"Data is diverse.\")\n",
    "\n",
    "print(final_submission.shape)\n",
    "\n",
    "final_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a19eca",
   "metadata": {
    "papermill": {
     "duration": 0.004848,
     "end_time": "2025-03-19T21:52:30.706665",
     "exception": false,
     "start_time": "2025-03-19T21:52:30.701817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9acd8b7",
   "metadata": {
    "papermill": {
     "duration": 0.004691,
     "end_time": "2025-03-19T21:52:30.716542",
     "exception": false,
     "start_time": "2025-03-19T21:52:30.711851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11165145,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 38.057601,
   "end_time": "2025-03-19T21:52:31.543026",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-19T21:51:53.485425",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
